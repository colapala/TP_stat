\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={TP Statistique},
            pdfauthor={Cédric Milinaire, Corentin Laharotte},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\title{TP Statistique}
\author{Cédric Milinaire, Corentin Laharotte}
\date{4 avril 2020}

\begin{document}
\maketitle

Voici le plan de ce qui sera fait dans le TP.

\hypertarget{visualisation-de-chemins}{%
\section{0. Visualisation de chemins}\label{visualisation-de-chemins}}

Lecture du fichier des villes :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{villes <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{'DonneesGPSvilles.csv'}\NormalTok{,}\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{,}\DataTypeTok{dec=}\StringTok{'.'}\NormalTok{,}\DataTypeTok{sep=}\StringTok{';'}\NormalTok{,}\DataTypeTok{quote=}\StringTok{"}\CharTok{\textbackslash{}"}\StringTok{"}\NormalTok{)}
\KeywordTok{str}\NormalTok{(villes)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    22 obs. of  5 variables:
##  $ EU_circo : Factor w/ 7 levels "Centre","Est",..: 6 6 4 2 7 4 2 1 2 4 ...
##  $ region   : Factor w/ 22 levels "Alsace","Aquitaine",..: 22 9 19 10 2 4 8 3 5 17 ...
##  $ ville    : Factor w/ 22 levels "Ajaccio","Amiens",..: 11 1 2 3 4 5 6 7 8 9 ...
##  $ latitude : num  45.7 41.9 49.9 47.2 44.8 ...
##  $ longitude: num  4.847 8.733 2.3 6.033 -0.567 ...
\end{verbatim}

Représentation des chemins par plus proches voisins et du chemin optimal
:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coord <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(villes}\OperatorTok{$}\NormalTok{longitude,villes}\OperatorTok{$}\NormalTok{latitude)}
\NormalTok{dist <-}\StringTok{ }\KeywordTok{distanceGPS}\NormalTok{(coord)}
\NormalTok{voisins <-}\StringTok{ }\KeywordTok{TSPnearest}\NormalTok{(dist)}

\NormalTok{pathOpt <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{21}\NormalTok{,}\DecValTok{13}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{17}\NormalTok{,}\DecValTok{16}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{19}\NormalTok{,}\DecValTok{15}\NormalTok{,}\DecValTok{18}\NormalTok{,}\DecValTok{11}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{22}\NormalTok{,}\DecValTok{14}\NormalTok{,}\DecValTok{12}\NormalTok{,}\DecValTok{2}\NormalTok{)}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}\DataTypeTok{mar=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\KeywordTok{plotTrace}\NormalTok{(coord[voisins}\OperatorTok{$}\NormalTok{chemin,], }\DataTypeTok{title=}\StringTok{'Plus proches voisins'}\NormalTok{)}
\KeywordTok{plotTrace}\NormalTok{(coord[pathOpt,], }\DataTypeTok{title=}\StringTok{'Chemin optimal'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{TPstat_CR_files/figure-latex/unnamed-chunk-2-1.pdf}

Les longueurs des trajets (à vol d'oiseau) valent respectivement, pour
la méthode des plus proches voisins :

\begin{verbatim}
## [1] 4303.568
\end{verbatim}

et pour la méthode optimale :

\begin{verbatim}
## [1] 3793.06
\end{verbatim}

Ceci illustre bien l'intérêt d'un algorithme de voyageur de commerce.
Nous allons dans la suite étudier les performances de cet algorithme.

\hypertarget{comparaison-dalgorithmes}{%
\section{1. Comparaison d'algorithmes}\label{comparaison-dalgorithmes}}

Dans cette partie, nous souhaitons comparer les méthodes repetitive\_nn,
nearest\_insertion, two\_opt, nearest, et branch. Pour cela, nous allons
générer des graphes aléatoires de 10 sommets, et tester les longueurs
des chemins calculés et le temps de calcul des différentes méthodes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{      n <-}\StringTok{ }\DecValTok{10}
\NormalTok{sommets <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{runif}\NormalTok{(n), }\DataTypeTok{y =} \KeywordTok{runif}\NormalTok{(n))}
\NormalTok{  couts <-}\StringTok{ }\KeywordTok{distance}\NormalTok{(sommets)}
\end{Highlighting}
\end{Shaded}

\hypertarget{longueur-des-chemins}{%
\subsection{1.1. Longueur des chemins}\label{longueur-des-chemins}}

Dans un premier temps, nous allons comparer les longueurs des chemins
hamiltoniens calculés par les 5 méthodes sur 50 réalisations de graphes
aléatoires.

\begin{itemize}
\tightlist
\item
  Représentation de la longueur des chemins hamiltoniens obtenus par
  différentes méthodes :
\end{itemize}

\includegraphics{TPstat_CR_files/figure-latex/unnamed-chunk-6-1.pdf}
L'affichage sous forme de boxplot nous permet de remarquer que : * la
méthode branch renvoie le plus souvent un chemin plus court que les
autres méthodes * la méthode nearest renvoie le plus souvent un chemin
plus long que les autres méthodes * la boîte de la méthode
repetitive\_nn est moins étendue que les boîtes obtenues par les autres
méthodes, ce qui nous permet de constater que 50\% des valeurs sont très
proches de la valeur médiane * la boîte de la méthode nearest\_insertion
est plus étendue que les boîtes obtenues par les autres méthodes, ce qui
nous permet de constater que 50\% des valeurs sont assez étendues autour
de la valeur médiane

L'affichage obtenu est assez cohérent puisqu'aucune méthode n'a de
valeur moyenne complètement absurde par rapport aux autre méthodes.

\begin{itemize}
\tightlist
\item
  test entre `nearest' et `branch'
\end{itemize}

On souhaite maintenant comparer les méthodes des plus proches voisins et
Branch\&Bound. On réalise donc un test sur l'espérance de chaque
méthode: Notre hypothèse nulle (H0) est que la moyenne des chemins
hamiltoniens obtenus avec la méthode des plus proches voisins est
inférieure ou égale à la moyenne des chemins hamiltoniens obtenus avec
la méthode Branch\&Bound. Notre hypothèse alternative (H1) est que la
moyenne des chemins hamiltoniens obtenus avec la méthode des plus
proches voisins est supérieure à la moyenne des chemins hamiltoniens
obtenus avec la méthode Branch\&Bound. (H0) \(m_{nn} - m_b <= 0\)
\textless{}=\textgreater{} \(m_{nn} <= m_b\) (H1) \$m\_\{nn\} - m\_b
\textgreater{} 0 \$ \textless{}=\textgreater{} \(m_{nn} > m_b\)

Nous allons ensuite tester si au seuil de 5\% la moyenne des chemins
hamiltoniens obtenus avec la méthode des plus proches voisins est
inférieure ou égale à la moyenne des chemins hamiltoniens obtenus avec
la méthode Branch\&Bound. Pour cela, nous allons faire une comparaison
d'échantillons gaussiens appariés.En effet, les deux méthodes étant
basées sur les mêmes graphes, les résultats obtenus ne peuvent pas être
considérés comme indépéndant. Région critique à 5\% : \{T \textgreater{}
t\_n-1;2a\}

On obtient une \(p-{valeur}\) de :

\begin{verbatim}
## [1] 7.011422e-12
\end{verbatim}

\begin{verbatim}
## [1] "a > t_a"
## [1] "On peut rejeter H0"
\end{verbatim}

-pvalue petite et plus petit que alpha On peut rejeter H0, et affirmer
avec un risque de 5\% que les chemins des plus proches voisins sont en
moyenne plus long que ceux de Branch\&Bound.

\begin{itemize}
\tightlist
\item
  tests 2 à 2
\end{itemize}

Ici (H0) mi=mj (H1) mi!=mj

\begin{verbatim}
## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  results and methods 
## 
##                   branch  nearest nearest_insertion repetitive_nn
## nearest           0.00078 -       -                 -            
## nearest_insertion 0.02272 0.94921 -                 -            
## repetitive_nn     0.94921 0.01702 0.20157           -            
## two_opt           0.09341 0.53849 0.94921           0.53849      
## 
## P value adjustment method: holm
\end{verbatim}

A COMMENTER

Si on accepte de se tromper de alpha=5\%, on rejette H0 si la pvaleur de
(i,j) est inférieure à alpha.

On rejette H0: - nearest branch - insertion branch - reptitve nearest

Avec un risque de 5\% nous pouvons affirmer que ces méthodes ne sont pas
similaires sur la longueur moyenne des chemins calculés

\hypertarget{temps-de-calcul}{%
\subsection{1.2. Temps de calcul}\label{temps-de-calcul}}

Comparaison des temps à l'aide du package microbenchmark.

Application de microbenchmark :

\begin{verbatim}
## Unit: microseconds
##                                  expr      min        lq      mean    median
##      TSPsolve(couts, "repetitive_nn") 3400.755 3594.6445 4010.6703 3963.3925
##  TSPsolve(couts, "nearest_insertion")  528.756  557.6420  662.1242  630.7850
##            TSPsolve(couts, "two_opt")  311.411  354.1235  461.3706  396.2985
##            TSPsolve(couts, "nearest")    8.213    9.2455   11.9623   11.5030
##             TSPsolve(couts, "branch") 1010.017 1787.1025 3128.3391 2577.0105
##         uq       max neval
##  4426.1780  4997.468    20
##   744.2235   913.987    20
##   571.4005   794.541    20
##    14.0765    16.901    20
##  3761.4730 11958.222    20
\end{verbatim}

-en moyenne ils sont tous a peu pres equivalent en parecequ'on ne peut
pas rejeter h0 pour tous sauf repitive nn -confirmer en regardant les
chiffres repetitve nn prend en moyenne au moins 2x plus de temps que les
autres

\hypertarget{etude-de-la-complexituxe9-de-lalgorithme-branch-and-bound}{%
\section{2. Etude de la complexité de l'algorithme Branch and
Bound}\label{etude-de-la-complexituxe9-de-lalgorithme-branch-and-bound}}

\hypertarget{comportement-par-rapport-au-nombre-de-sommets-premier-moduxe8le}{%
\subsection{2.1. Comportement par rapport au nombre de sommets : premier
modèle}\label{comportement-par-rapport-au-nombre-de-sommets-premier-moduxe8le}}

Récupération du temps sur 10 graphes pour différentes valeurs de \(n\).

\includegraphics{TPstat_CR_files/figure-latex/unnamed-chunk-14-1.pdf}
Les nombres représentés sont les numéros de colonnes de la valeur à la
nième ligne !

Ajustement du modèle linéaire de \(\log(temps)^2\) en fonction de \(n\).

\begin{verbatim}
## 
## Call:
## lm(formula = vect_temps ~ vect_dim)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -73.05 -20.21   4.07  21.17  60.25 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  57.6751     5.3640   10.75   <2e-16 ***
## vect_dim     14.1635     0.4138   34.22   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 26.43 on 168 degrees of freedom
## Multiple R-squared:  0.8746, Adjusted R-squared:  0.8738 
## F-statistic:  1171 on 1 and 168 DF,  p-value: < 2.2e-16
\end{verbatim}

COMMENTER

\begin{itemize}
\tightlist
\item
  on peut voire que log(tmps\^{}2) en fonction de n suit une courbe
  lineaire (R squareed = 0.8705) du coups le temps est une fonction
  exponentielle de n i.e la complexite de temps est exponentielle.
\end{itemize}

Analyse de la validité du modèle :

\begin{itemize}
\tightlist
\item
  pertinence des coefficients et du modèle
\end{itemize}

\includegraphics{TPstat_CR_files/figure-latex/unnamed-chunk-16-1.pdf}

COMMENTER

\begin{itemize}
\tightlist
\item
  étude des hypothèses sur les résidus.
\end{itemize}

PAS SUR QUE LE PARAMETRE SOIT temps.lm

(H0) les résidus suivent une loi normale (H1) les résidus ne suivent pas
une loi normale

On prend un risque alpha=5\%

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  residuals(temps.lm)
## W = 0.97241, p-value = 0.001822
\end{verbatim}

\begin{verbatim}
## [1] "p-valeur < alpha"
## [1] "On peut rejeter H0"
\end{verbatim}

On rejette H0, donc nous pouvons affirmer que les résidus ne suivent pas
une loi normale.

\includegraphics{TPstat_CR_files/figure-latex/unnamed-chunk-19-1.pdf}

\hypertarget{comportement-par-rapport-au-nombre-de-sommets-uxe9tude-du-comportement-moyen}{%
\subsection{2.2. Comportement par rapport au nombre de sommets : étude
du comportement
moyen}\label{comportement-par-rapport-au-nombre-de-sommets-uxe9tude-du-comportement-moyen}}

Récupération du temps moyen.

Ajustement du modèle linéaire de \(\log(temps.moy)^2\) en fonction de
\(n\).

\begin{verbatim}
## 
## Call:
## lm(formula = vect_temps_moy ~ vect_dim_moy)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -36.68 -11.93  10.32  13.16  27.21 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)    57.510     12.676   4.537 0.000393 ***
## vect_dim_moy   14.574      0.978  14.903 2.13e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 19.75 on 15 degrees of freedom
## Multiple R-squared:  0.9367, Adjusted R-squared:  0.9325 
## F-statistic: 222.1 on 1 and 15 DF,  p-value: 2.128e-10
\end{verbatim}

Analyse de la validité du modèle :

\begin{itemize}
\tightlist
\item
  pertinence des coefficients et du modèle
\end{itemize}

\includegraphics{TPstat_CR_files/figure-latex/unnamed-chunk-22-1.pdf}

\begin{itemize}
\tightlist
\item
  étude des hypothèses sur les résidus.
\end{itemize}

PAS SUR QUE LE PARAMETRE SOIT temps.lm\_moy

(H0) les résidus suivent une loi normale (H1) les résidus ne suivent pas
une loi normale

On prend un risque alpha=5\%

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  residuals(temps.lm_moy)
## W = 0.88933, p-value = 0.04518
\end{verbatim}

\begin{verbatim}
## [1] "p-valeur < alpha"
## [1] "On peut rejeter H0"
\end{verbatim}

On ne peut pas rejeter H0. Donc on peut assurer avec un risque de 5\%
que les résidus suivent une loi normale. Validité du modèle ???

\hypertarget{comportement-par-rapport-uxe0-la-structure-du-graphe}{%
\subsection{2.3. Comportement par rapport à la structure du
graphe}\label{comportement-par-rapport-uxe0-la-structure-du-graphe}}

Lecture du fichier `DonneesTSP.csv'.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data.graph <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{read.csv}\NormalTok{(}\StringTok{'DonneesTSP.csv'}\NormalTok{))}
\NormalTok{data.graph}\OperatorTok{$}\NormalTok{dim<-}\KeywordTok{sqrt}\NormalTok{(data.graph}\OperatorTok{$}\NormalTok{dim)}
\KeywordTok{str}\NormalTok{(data.graph)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    70 obs. of  8 variables:
##  $ tps      : num  53692 144081 997803 2553322 6333009 ...
##  $ dim      : num  2 2.45 2.83 3.16 3.46 ...
##  $ mean.long: num  0.391 0.442 0.334 0.276 0.254 ...
##  $ mean.dist: num  0.665 0.592 0.537 0.506 0.502 ...
##  $ sd.dist  : num  0.276 0.259 0.246 0.238 0.227 ...
##  $ mean.deg : num  3 5 7 9 11 13 15 17 19 3 ...
##  $ sd.deg   : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ diameter : num  1 1 1 1 1 1 1 1 1 1 ...
\end{verbatim}

Ajustement du modèle linéaire de \(\log(temps.moy)^2\) en fonction de
toutes les variables présentes. Modèle sans constante.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.complete <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{log}\NormalTok{(tps)}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ data.graph)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{step}\NormalTok{(model.complete))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Start:  AIC=-165.23
## log(tps) ~ dim + mean.long + mean.dist + sd.dist + mean.deg + 
##     sd.deg + diameter
## 
##             Df Sum of Sq     RSS      AIC
## - diameter   1    0.0145  5.2711 -167.038
## <none>                    5.2566 -165.230
## - sd.deg     1    0.2182  5.4748 -164.384
## - mean.dist  1    0.3014  5.5581 -163.327
## - mean.deg   1    0.8757  6.1324 -156.444
## - mean.long  1    3.6951  8.9517 -129.965
## - sd.dist    1    4.4335  9.6902 -124.417
## - dim        1   17.3311 22.5877  -65.176
## 
## Step:  AIC=-167.04
## log(tps) ~ dim + mean.long + mean.dist + sd.dist + mean.deg + 
##     sd.deg
## 
##             Df Sum of Sq     RSS      AIC
## <none>                    5.2711 -167.038
## - sd.deg     1    0.2065  5.4776 -166.349
## - mean.dist  1    0.6554  5.9265 -160.835
## - mean.deg   1    0.9820  6.2531 -157.080
## - mean.long  1    3.8220  9.0931 -130.869
## - sd.dist    1    4.9133 10.1844 -122.935
## - dim        1   18.7788 24.0499  -62.785
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm(formula = log(tps) ~ dim + mean.long + mean.dist + sd.dist + 
##     mean.deg + sd.deg, data = data.graph)
## 
## Coefficients:
## (Intercept)          dim    mean.long    mean.dist      sd.dist     mean.deg  
##    6.396008     3.444077    -4.854857    -0.002284     0.004883    -0.140823  
##      sd.deg  
##    0.126916
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new_model <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{formula =} \KeywordTok{log}\NormalTok{(tps) }\OperatorTok{~}\StringTok{ }\NormalTok{dim }\OperatorTok{+}\StringTok{ }\NormalTok{mean.long }\OperatorTok{+}\StringTok{ }\NormalTok{mean.dist }\OperatorTok{+}\StringTok{ }\NormalTok{sd.dist }\OperatorTok{+}\StringTok{ }
\StringTok{    }\NormalTok{mean.deg }\OperatorTok{+}\StringTok{ }\NormalTok{sd.deg, }\DataTypeTok{data =}\NormalTok{ data.graph)}
\NormalTok{shapiroTest_aic<-}\KeywordTok{shapiro.test}\NormalTok{(}\KeywordTok{residuals}\NormalTok{(new_model))}
\KeywordTok{print}\NormalTok{(shapiroTest_aic)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  residuals(new_model)
## W = 0.98094, p-value = 0.3641
\end{verbatim}

Mise en \oe uvre d'une sélection de variables pour ne garder que les
variables pertinentes.

Analyse de la validité du modèle :

\begin{itemize}
\item
  pertinence des coefficients et du modèle,
\item
  étude des hypothèses sur les résidus.
\end{itemize}

\end{document}
