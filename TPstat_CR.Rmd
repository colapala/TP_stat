---
title: "TP Statistique"
author: "Cédric Milinaire, Corentin Laharotte"
date: "4 avril 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## il est possible qu'avant d'installer le package TSPpackage vous deviez installer ou ré-installer Rcpp
#install.packages('Rcpp')

# install.packages('./TSPpackage_1.0.tar.gz',repos=NULL,type='bin') ## pour linux
# install.packages('./TSPpackage_1.0.zip',repos=NULL,type='bin')    ## pour windows
## je ne peux pas fournir de package pour mac...

## Appels aux packages, après les avoir installés !
library(sp)
library(maps)
library(microbenchmark)
library(TSP)
library(TSPpackage)

# fixe la graine
set.seed(150)
```
Voici le plan de ce qui sera fait dans le TP.

# 0. Visualisation de chemins

Lecture du fichier des villes :

```{r, echo=TRUE}
villes <- read.csv('DonneesGPSvilles.csv',header=TRUE,dec='.',sep=';',quote="\"")
str(villes)
```
Représentation des chemins par plus proches voisins et du chemin optimal :
```{r, echo=TRUE}
coord <- cbind(villes$longitude,villes$latitude)
dist <- distanceGPS(coord)
voisins <- TSPnearest(dist)

pathOpt <- c(1,8,9,4,21,13,7,10,3,17,16,20,6,19,15,18,11,5,22,14,12,2)

par(mfrow=c(1,2),mar=c(1,1,2,1))
plotTrace(coord[voisins$chemin,], title='Plus proches voisins')
plotTrace(coord[pathOpt,], title='Chemin optimal')
```


Les longueurs des trajets (à vol d'oiseau) valent respectivement, pour la méthode des plus proches voisins :
```{r, echo=FALSE}
voisins$longueur
```
et pour la méthode optimale :
```{r, echo=FALSE}
calculeLongueur(dist,pathOpt)
```

Ceci illustre bien l'intérêt d'un algorithme de voyageur de commerce. Nous allons dans la suite étudier les performances de cet algorithme.


# 1. Comparaison d'algorithmes

Dans cette partie, nous souhaitons comparer les méthodes repetitive_nn, nearest_insertion, two_opt, nearest, et branch. Pour cela, nous allons générer des graphes aléatoires de 10 sommets, et tester les longueurs des chemins calculés et le temps de calcul des différentes méthodes.

```{r, echo=TRUE}
      n <- 10
sommets <- data.frame(x = runif(n), y = runif(n))
  couts <- distance(sommets)
```

## 1.1. Longueur des chemins

Dans un premier temps, nous allons comparer les longueurs des chemins hamiltoniens calculés par les 5 méthodes sur 50 réalisations de graphes aléatoires.

### Représentation de la longueur des chemins hamiltoniens obtenus par différentes méthodes :
   
```{r, echo=FALSE}
cheminRepetitive <- vector()
cheminNearestIns <- vector()
chemin2Opt <- vector()
cheminNearest <- vector()
cheminBranch <- vector()

for (i in 1:50){
  # Généreation de graphe aléatoire
  n <- 10
  sommets <- data.frame(x = runif(n), y = runif(n))
  couts <- distance(sommets)
  
  # methode repetitive
  cheminRepetitive<-c(cheminRepetitive, TSPsolve(couts,"repetitive_nn"))
  #methode nearest insertion
  cheminNearestIns<-c(cheminNearestIns, TSPsolve(couts,"nearest_insertion"))
  #methode two Opt 
  chemin2Opt<-c(chemin2Opt, TSPsolve(couts,"two_opt"))
  #methode nearest 
  cheminNearest<-c(cheminNearest, TSPsolve(couts,"nearest"))
  #methode branch
  cheminBranch<-c(cheminBranch, TSPsolve(couts,"branch"))
}

boxplot(cheminRepetitive,cheminNearestIns,chemin2Opt,cheminNearest,cheminBranch,
        main="longueur des chemins hamiltoniens donnés par 5 méthodes",
        names=c("repetitive_nn","nearest_insertion", "two_opt", "nearest", "branch"),
        cex.axis=0.7299
        )
```
L'affichage sous forme de boxplot nous permet de remarquer que :
   * la méthode branch renvoie le plus souvent un chemin plus court que les autres méthodes
   * la méthode nearest renvoie le plus souvent un chemin plus long que les autres méthodes
   * la boîte de la méthode repetitive_nn est moins étendue que les boîtes obtenues par les autres méthodes, ce qui nous permet de constater que 50% des valeurs sont très proches de la valeur médiane
   * la boîte de la méthode nearest_insertion est plus étendue que les boîtes obtenues par les autres méthodes, ce qui nous permet de constater que 50% des valeurs sont assez étendues autour de la valeur médiane \\
  
L'affichage obtenu est assez cohérent puisqu'aucune méthode n'a de valeur moyenne complètement absurde par rapport aux autre méthodes.

   * test entre 'nearest' et 'branch'
 
On souhaite maintenant comparer les méthodes des plus proches voisins et Branch&Bound.\\
On réalise donc un test sur l'espérance de chaque méthode.\\
Notre hypothèse nulle (H0) est que la moyenne des chemins hamiltoniens obtenus avec la méthode des plus proches voisins est inférieure ou égale à la moyenne des chemins hamiltoniens obtenus avec la méthode Branch&Bound. Notre hypothèse alternative (H1) est que la moyenne des chemins hamiltoniens obtenus avec la méthode des plus proches voisins est supérieure à la moyenne des chemins hamiltoniens obtenus avec la méthode Branch&Bound.\\
  (H0) $m_{nn} - m_b <= 0$    <=>  $m_{nn} <= m_b$ \\
  (H1) $m_{nn} - m_b > 0$     <=> $m_{nn} > m_b$ \\
 
Nous allons ensuite tester si au seuil de 5% la moyenne des chemins hamiltoniens obtenus avec la méthode des plus proches voisins est inférieure ou égale à la moyenne des chemins hamiltoniens obtenus avec la méthode Branch&Bound. \\
Pour cela, nous allons faire une comparaison d'échantillons gaussiens appariés.En effet, les deux méthodes étant basées sur les mêmes graphes, les résultats obtenus ne peuvent pas être considérés comme indépéndant.\\

On pose $a=0.05$.

```{r, echo=FALSE}
n<-50
# risque = 5%
a<-0.05
```
On obtient une $p_{valeur}$ de :
```{r, echo=FALSE}
t_a <- t.test(cheminBranch,cheminNearest,mu = 0 ,paired=TRUE,altermative="greater")
print(t_a$p.value)
```


```{r, echo=FALSE}
if(a>t_a$p.value){
  print("p_valeur < a")
  print("On peut rejeter H0")
} else {
   print("p_valeur >= a")
   print("On ne peut pas rejeter H0")
}
```
On observe que la $p_{valeur}$ obtenue est strictement inférieure à a. \\
On peut rejeter H0, et affirmer avec un risque de 5% que les chemins hamiltoniens obtenus avec la méthode des plus proches voisins sont en moyenne plus longs que ceux obtenus avec la méthode Branch&Bound.

   * tests 2 à 2 
On souhaite maintenant comparer 2 à 2 les longueurs moyennes des chemins hamiltoniens obtenus par les 5 méthodes vues précédemment.\\
On réalise donc un test sur l'espérance de chaque méthode. \\
Soit i, j deux méthodes différentes .Notre hypothèse nulle (H0) est que la moyenne des chemins hamiltoniens obtenus avec la méthode i est égale à la moyenne des chemins hamiltoniens obtenus avec la méthode j. Notre hypothèse alternative (H1) est que la moyenne des chemins hamiltoniens obtenus avec la méthode i est différente de la moyenne des chemins hamiltoniens obtenus avec la méthode j.\\
(H0) $mi=mj$ \\
(H1) $mi!=mj$ \\

Nous avons lancé 10 tests simultanés, et obtenus les résulats suivants : \\
  
```{r, echo=FALSE}
methodsRepetitive <- vector()
methodsNearestIns <- vector()
methods2Opt <- vector()
methodsNearest <- vector()
methodsBranch <- vector()

for (i in 1:50){
  methodsRepetitive<-c(methodsRepetitive, "repetitive_nn")
  methodsNearestIns<-c(methodsNearestIns, "nearest_insertion")
  methods2Opt<-c(methods2Opt, "two_opt")
  methodsNearest<-c(methodsNearest, "nearest")
  methodsBranch<-c(methodsBranch, "branch")
}
methods<-c(methodsRepetitive, methodsNearestIns, methods2Opt, methodsNearest, methodsBranch)
results<-c(cheminRepetitive, cheminNearestIns, chemin2Opt, cheminNearest, cheminBranch)

#test
pairwise.t.test(results,methods,adjust.method="bonferroni")
```
Nous allons tester si au seuil de 5%, notre hypothèse H0 est vérifiée.\\ \\

Si on accepte un risque alpha=5%, on rejette notre hypothèse nulle (H0) si la $p_{valeur}$ obtenue à l'indice [i,j] est inférieure à alpha.\\ 
Donc, si la valeur à l'indice [i,j] est inférieure à alpha, nous pouvons affirmer que la moyenne des chemins hamiltoniens obtenus avec la méthode i est différente de celle obtenue avec la méthode j.\\

En appliquant ce principe à nos résultats, nous pouvons dire que :
  - les méthodes nearest et branch ont des moyennes de chemins calculés différentes
  - les méthodes nearest_insertion et branch ont des moyennes de chemins calculés différentes   - les méthodes nearest et repetitive_nn ont des moyennes de chemins calculés différentes
  
Pour les autres méthodes, nous ne pouvons pas rejeter l'hypothèse d'après laquelle la moyenne des chemins hamiltoniens obtenus avec la méthode i est égale à la moyenne des chemins hamiltoniens obtenus avec la méthode j.

## 1.2. Temps de calcul

Nous souhaitons maintenant comparer les temps d'éxécution des différentes méthodes de calcul de longueur de chemin hamiltonien sur 20 graphes de 10 sommets générés aléatoirement.\\

Nous avons utilisé la focntion benchmark pour réaliser des statistiques d'exécution pour chaque méthode. 
Nous avons réalisé des tests sur les temps moyens d'exécution de chaque méthode : \\
Soit i, j deux méthodes différentes .Notre hypothèse nulle (H0) est que le temps moyen d'exécution de la méthode i est égale au temps moyen d'exécution de la méthode j. Notre hypothèse alternative (H1) est que le temps moyen d'exécution de la méthode i est différent du temps moyen d'exécution de la méthode j.\\
Le résultat de ces tests est représenté par une lettre dans la colonne X du tableau ci-dessous. Une même lettre est attribuée aux méthodes pour lequelles H0 n'est pas rejetée. Deux méthodes ayant des lettres différentes ont des temps d'exécution moyens différents.\\

```{r, echo=FALSE}
essai<-data.frame(microbenchmark(TSPsolve(couts,"repetitive_nn"), TSPsolve(couts,"nearest_insertion"), TSPsolve(couts,"two_opt"), TSPsolve(couts,"nearest"), TSPsolve(couts,"branch"), 
               times=20, 
               setup={
                 n <- 10
                 sommets <- data.frame(x = runif(n), y = runif(n))
                 couts <- distance(sommets)
                }
            ))

```
Nous pouvons remarquer que les méthodes nearest_insertion, two_opt et nearest ont un temps d'exécution moyen similaires. Les méthodes sont classées 'a', ce qui montre que ce sont les méthodes les plus rapides des 5 méthodes proposées. De plus, on ne peut pas rejeter le fait que, pour les méthodes citées précédemment, le temps moyen d'exécution de la méthode i est égal au temps moyen d'exécution de la méthode j. 
Les méthodes repetitive_nn et branch ont une durée d'exécution moyenne supérieure aux autres. \\
La méthode repetitive_nn est classée 'd', ce qui fait que l'on peut affirmer que le temps moyen d'exécution de cette méthode est différent du temps moyen d'exécution des autres méthodes. De plus, comme les lettres {a, b, c, ...} sont attribuées en fonction du temps d'exécution ('a' pour la plus rapide, ...), on peut en déduire que le temps moyen d'exécution de repetitive_nn est plus important que le temps moyens des autres méthodes. \\
Par la même réflexion que celle faite précédemment, nous pouvons remarquer que branch est classé 'b', et a un temps d'exécution moyen plus long que les trois méthodes classées 'a'. Cependant, il a un temps moyen d'exécution inférieur à la méthode repetitive_nn. 

### commentaire prof
Tout les membres d’un meme groupe n’ont pas de différence significative pour leurs moyenne et les groupes
{a, b, c, d, . . . } sont rangés de manière croisante.
Exemple - si variables X et variable Y sont dans le groupe a alors m X ' m Y où plutot qu’il n’a pas pu être
mis en évidence une différence significative entre les deux. - si variables X et variable Y sont dans le groupe
a et b alors m X 6 = m Y significativement. Et comme {a, b, c, d, . . . } sont rangés de manière croisante alors
m a < m b donc m X < m Y



# 2. Etude de la complexité de l'algorithme Branch and Bound

```{r, echo=FALSE}
n <- 10
sommets <- data.frame(x = runif(n), y = runif(n))
couts <- distance(sommets)
```

## 2.1. Comportement par rapport au nombre de sommets : premier modèle

```{r, echo=FALSE}
seq_max <- 20
seqn <- seq(4,seq_max,1)
number_exec <- seq_max-3

temps<-matrix(,nrow = number_exec, ncol = 10)
for (i in 1:number_exec){
  temps[i,]<-microbenchmark(TSPsolve(couts, method = "branch"),
                            times = 10,
                            setup = { n <- seqn[i]
                            couts <- distance(cbind(x = runif(n), y = runif(n)))}
                            )$time
}
```

Récupération du temps sur 10 graphes pour différentes valeurs de $n$.

```{r, echo=FALSE}
par(mfrow=c(1,2)) 
matplot(seqn, temps, xlab="n", ylab="temps")
matplot(seqn, log(temps)^2, xlab="n", ylab=expression(log(temps)^2))
```
Les nombres représentés sont les numéros de colonnes de la valeur à la nième ligne !

Ajustement du modèle linéaire de $\log(temps)^2$ en fonction de $n$.

```{r, echo=FALSE}
vect_temps <- log(as.vector(temps))^2
vect_dim <- rep(seqn,times=10)
temps.lm <- lm(vect_temps~vect_dim)
summary(temps.lm)
```

COMMENTER

- on peut voire que log(tmps^2) en fonction de n suit une courbe lineaire (R squareed = 0.8705) du coups le temps est une fonction exponentielle de n i.e la complexite de temps est exponentielle. 



Analyse de la validité du modèle : 

Le modèle nous renvoie une fonction de type: $Y = aX + b + \epsilon$. En effet nous avons les paramètres suivants: 
$a = 14.7$, $b = 68.6$. Il reste donc a savoir les coéfficients et donc le modèle sont pertinents. Nous allons tous d'abord analyser la pertinence des coefficients puis celle du modèle en géneral. 

  * L'analyse de $a$, permet d'établir un premier résultat quantifiant la significativité du modèle. En effet nous allons tester la significativité de a via le test statistique: $(H0) : a = 0$ contre $(H1) : a \neq 0$. La p-value de celui-ci ce retrouve dans le tableau summary(temps.lm) et est $2.2e-16$. Nous sommes donc capable d'affiirmer avec un risque de  de moins que 0.1% (chiffre arbitraire plus grand que $2.2e-14$ )  que $a$ est significatif.  
  * L'analyse de $b$ est la moins importante. Il nous indique seulement l'importance de l'intercept. Le test statistique est analogique à $a$. Ca p-value est aussi $2.2e-16$ Nous sommes donc capable d'affiirmer avec un risque de  de moins que 0.1% (chiffre arbitraire plus grand que $2.2e-14$ )  que l'intercept est utile.  
  * Nous pouvons maintenant passé a l'analyse des résidus: 
    * Pour ceci nous allons tous d'abord nous intéréssé a plusieurs graphique:

```{r, echo=FALSE}
par(mfrow=c(2,2)) 
plot(temps.lm)
```
 
 
 *Residuals vs Fitted: La courbe n'est pas complètement horizontal. Il y'a donc un léger effet d'échelle. 
 * Normal Q-Q: les points sont proches de la bissectrice, la distribution des résidus est donc similaire à la distribution normale. Nous voyons une légère séparation au niveau des queues des distribution. 
 *Scale Location: cette courbe représente la meme chose que la première seulement avec dles résisu normalisé. On remarque que la courbe est bien honrizontal que le léger effet d'échelle disparait. 
 *Pour la distance de cook nous avons préfére prendre le graphique suivant: Nous voyons qu'aucun résidu a une distance plus grande que 0.05 et que la plus part on une distance inferieure a 0.01. Ceci indique que le bon fit du modèle.
 
 
```{r, echo=FALSE}
plot(temps.lm,which=5)
```

  * Il est aussi possible d'éffectuer un test statistique sur les résidus. En effet s'ils suivent une loi normale ceci indique le bon fit du modèle. 
  * Définissons: 
    *$(H0)$ les résidus suivent une loi normale
    *$(H1)$ les résidus ne suivent pas une loi normale
  * Pour tester ceci nous pouvons efféctuer un test de shapiro. 
  

```{r, echo=FALSE}
shapiroTest<-shapiro.test(residuals(temps.lm))
print(shapiroTest)
```

```{r, echo=FALSE}
#risque 5%
alpha=0.05
if(shapiroTest$p.value < alpha){
  print("p-valeur < alpha")
  print("On peut rejeter H0")
}else{
  print("p-valeur >= alpha")
  print("On ne peut pas rejeter H0")
}
```
On ne peut rejetter H0, donc nous pouvons affirmer que les résidusne suivent une loi normale. Ce qui indique un modèle pertinent. 


## 2.2. Comportement par rapport au nombre de sommets : étude du comportement moyen
L'explication des résultats étants similaire a 2.1, nous allons simplement afficher nos résultats.\\
Récupération du temps moyen.

```{r, echo=FALSE}
temps.moy<-rowMeans(temps)
```

Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de $n$.

```{r, echo=FALSE}
vect_temps_moy <- log(as.vector(temps.moy))^2
vect_dim_moy <- rep(seqn)
temps.lm_moy <- lm(vect_temps_moy~vect_dim_moy)
summary(temps.lm_moy)
```

Analyse de la validité du modèle : 

  * $a$ pertinent $p-value = 2.3*10^{-9}$
  * $b$ pertinent $p-value = 0.000476$
  
  
```{r, echo=FALSE}
par(mfrow=c(2,2)) 
plot(temps.lm_moy)
```

 
 *Residuals vs Fitted: La courbe n'est pas du tou  horizontal. Il y'a donc un important effet d'échelle. 
 * Normal Q-Q: Les distributions sont identiques.
 *Scale Location: L'effet d'échelle disparait. Le nuage de point est sans structure. Ce qui indique la qualité du modèle. 

  
  * Il est aussi possible d'éffectuer un test statistique sur les résidus. En effet s'ils suivent une loi normale ceci indique le bon fit du modèle. 
  * Définissons: 
    *$(H0)$ les résidus suivent une loi normale
    *$(H1)$ les résidus ne suivent pas une loi normale
  * Pour tester ceci nous pouvons efféctuer un test de shapiro. 
  
(H0) les résidus suivent une loi normale
(H1) les résidus ne suivent pas une loi normale

On prend un risque alpha=5%
  
```{r, echo=FALSE}
shapiroTest_moy<-shapiro.test(residuals(temps.lm_moy))
print(shapiroTest_moy)
```

```{r, echo=FALSE}
#risque 5%
alpha=0.05
if(shapiroTest_moy$p.value < alpha){
  print("p-valeur < alpha")
  print("On peut rejeter H0")
}else{
  print("p-valeur >= alpha")
  print("On ne peut pas rejeter H0")
}
```
On ne peut pas rejeter H0. Donc on peut assurer avec un risque de 5% que les résidus suivent une loi normale. Ceci valide donc le modèle. 


## 2.3. Comportement par rapport à la structure du graphe

Lecture du fichier 'DonneesTSP.csv'.

```{r, echo=TRUE}
data.graph <- data.frame(read.csv('DonneesTSP.csv'))
data.graph$dim<-sqrt(data.graph$dim)
str(data.graph)
```




Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de toutes les variables présentes. Modèle sans constante.

```{r, echo=TRUE}
model.complete <- lm(log(tps)~., data = data.graph)
```



```{r, echo=TRUE}
(step(model.complete))
```





```{r, echo=TRUE}
new_model <- lm(formula = log(tps) ~ dim + mean.long + mean.dist + sd.dist + 
    mean.deg + sd.deg, data = data.graph)
shapiroTest_aic<-shapiro.test(residuals(new_model))
print(shapiroTest_aic)
```



Mise en \oe uvre d'une sélection de variables pour ne garder que les variables pertinentes.

Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.

