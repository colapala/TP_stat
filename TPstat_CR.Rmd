---
title: "TP Statistique"
author: "Cédric Milinaire, Corentin Laharotte"
date: "4 avril 2020"
output:
  pdf_document: default
  toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## il est possible qu'avant d'installer le package TSPpackage vous deviez installer ou ré-installer Rcpp
#install.packages('Rcpp')

# install.packages('./TSPpackage_1.0.tar.gz',repos=NULL,type='bin') ## pour linux
# install.packages('./TSPpackage_1.0.zip',repos=NULL,type='bin')    ## pour windows
## je ne peux pas fournir de package pour mac...

## Appels aux packages, après les avoir installés !
library(sp)
library(maps)
library(microbenchmark)
library(TSP)
library(TSPpackage)

# fixe la graine
set.seed(150)
```

# 0. Visualisation de chemins

Lecture du fichier des villes :

```{r, echo=FALSE}
villes <- read.csv('DonneesGPSvilles.csv',header=TRUE,dec='.',sep=';',quote="\"")
```
Représentation des chemins par plus proches voisins et du chemin optimal :
```{r, echo=TRUE}
coord <- cbind(villes$longitude,villes$latitude)
dist <- distanceGPS(coord)
voisins <- TSPnearest(dist)

pathOpt <- c(1,8,9,4,21,13,7,10,3,17,16,20,6,19,15,18,11,5,22,14,12,2)

par(mfrow=c(1,2),mar=c(1,1,2,1))
plotTrace(coord[voisins$chemin,], title='Plus proches voisins')
plotTrace(coord[pathOpt,], title='Chemin optimal')
```


Les longueurs des trajets (à vol d'oiseau) valent respectivement, pour la méthode des plus proches voisins :
```{r, echo=FALSE}
voisins$longueur
```
et pour la méthode optimale :
```{r, echo=FALSE}
calculeLongueur(dist,pathOpt)
```

Ceci illustre bien l'intérêt d'un algorithme de voyageur de commerce. Nous allons dans la suite étudier les performances de cet algorithme.


# 1. Comparaison d'algorithmes

Dans cette partie, nous souhaitons comparer les méthodes repetitive_nn, nearest_insertion, two_opt, nearest, et branch. Pour cela, nous allons générer des graphes aléatoires de 10 sommets, et tester les longueurs des chemins calculés et le temps de calcul des différentes méthodes.

```{r, echo=TRUE}
      n <- 10
sommets <- data.frame(x = runif(n), y = runif(n))
  couts <- distance(sommets)
```

## 1.1. Longueur des chemins

Dans un premier temps, nous allons comparer les longueurs des chemins hamiltoniens calculés par les 5 méthodes sur 50 réalisations de graphes aléatoires.

### Représentation de la longueur des chemins hamiltoniens obtenus par différentes méthodes :
   
```{r, echo=FALSE}
cheminRepetitive <- vector()
cheminNearestIns <- vector()
chemin2Opt <- vector()
cheminNearest <- vector()
cheminBranch <- vector()

for (i in 1:50){
  # Généreation de graphe aléatoire
  n <- 10
  sommets <- data.frame(x = runif(n), y = runif(n))
  couts <- distance(sommets)
  
  # methode repetitive
  cheminRepetitive<-c(cheminRepetitive, TSPsolve(couts,"repetitive_nn"))
  #methode nearest insertion
  cheminNearestIns<-c(cheminNearestIns, TSPsolve(couts,"nearest_insertion"))
  #methode two Opt 
  chemin2Opt<-c(chemin2Opt, TSPsolve(couts,"two_opt"))
  #methode nearest 
  cheminNearest<-c(cheminNearest, TSPsolve(couts,"nearest"))
  #methode branch
  cheminBranch<-c(cheminBranch, TSPsolve(couts,"branch"))
}

boxplot(cheminRepetitive,cheminNearestIns,chemin2Opt,cheminNearest,cheminBranch,
        main="Longueur des chemins hamiltoniens donnés par 5 méthodes",
        names=c("repetitive_nn","nearest_insertion", "two_opt", "nearest", "branch"),
        cex.axis=0.7299
        )
```


L'affichage sous forme de boxplot nous permet de remarquer que :

- la méthode \texttt{branch} renvoie le plus souvent un chemin plus court que les autres méthodes
- la méthode \texttt{nearest} renvoie le plus souvent un chemin plus long que les autres méthodes
- la boîte de la méthode \texttt{repetitive\_nn} est moins étendue que les boîtes obtenues par les autres méthodes, ce qui nous permet de constater que 50% des valeurs sont très proches de la valeur médiane
- la boîte de la méthode  \texttt{nearest\_insertion} est plus étendue que les boîtes obtenues par les autres méthodes, ce qui nous permet de constater que 50% des valeurs sont assez étendues autour de la valeur médiane   
    
L'affichage obtenu est assez cohérent puisqu'aucune méthode n'a de valeur médiane complètement absurde par rapport aux autre méthodes.

### Test entre 'nearest' et 'branch'
 
On souhaite maintenant comparer les méthodes des plus proches voisins et Branch&Bound.  
On réalise donc un test sur l'espérance de chaque méthode.  
  
Notre hypothèse nulle (H0) est que la moyenne des chemins hamiltoniens obtenus avec la méthode des plus proches voisins est inférieure ou égale à la moyenne des chemins hamiltoniens obtenus avec la méthode Branch&Bound. Notre hypothèse alternative (H1) est que la moyenne des chemins hamiltoniens obtenus avec la méthode des plus proches voisins est supérieure à la moyenne des chemins hamiltoniens obtenus avec la méthode Branch&Bound. 
  
  $(H_0)\ m_{nn} - m_b \leq 0 \Leftrightarrow  m_{nn} \leq m_b$   
  $(H_1)\ m_{nn} - m_b > 0       \Leftrightarrow m_{nn} > m_b$   
 
Nous allons ensuite tester si au seuil de 5% la moyenne des chemins hamiltoniens obtenus avec la méthode des plus proches voisins est inférieure ou égale à la moyenne des chemins hamiltoniens obtenus avec la méthode Branch&Bound.   
Pour cela, nous allons faire une comparaison d'échantillons gaussiens appariés. En effet, les deux méthodes étant basées sur les mêmes graphes, les résultats obtenus ne peuvent pas être considérés comme indépéndant.  

On pose $a=0.05$.

```{r, echo=FALSE}
n<-50
# risque = 5%
a<-0.05
```
On obtient une $p_{valeur}$ de :
```{r, echo=FALSE}
t_a <- t.test(cheminBranch,cheminNearest,mu = 0 ,paired=TRUE,altermative="greater")
print(t_a$p.value)
```


```{r, echo=FALSE}
if(a>t_a$p.value){
  print("p_valeur < a")
  print("On peut rejeter H0")
} else {
   print("p_valeur >= a")
   print("On ne peut pas rejeter H0")
}
```
On observe que la $p_{valeur}$ obtenue est strictement inférieure à a.   
On peut rejeter H0, et affirmer avec un risque de 5% que la moyenne des chemins hamiltoniens obtenus avec la méthode des plus proches voisins est supérieure à la moyenne des chemins hamiltoniens obtenus avec la méthode de Branch&Bound.

### Tests 2 à 2 
On souhaite maintenant comparer 2 à 2 les longueurs moyennes des chemins hamiltoniens obtenus par les 5 méthodes vues précédemment.  
  
On réalise donc un test sur l'espérance de chaque méthode.   
Soit i, j deux méthodes différentes. Notre hypothèse nulle $(H_0)$ est que la moyenne des chemins hamiltoniens obtenus avec la méthode i est égale à la moyenne des chemins hamiltoniens obtenus avec la méthode j. Notre hypothèse alternative $(H_1)$ est que la moyenne des chemins hamiltoniens obtenus avec la méthode i est différente de la moyenne des chemins hamiltoniens obtenus avec la méthode j.  
  
$(H_0) \ mi=mj$   
$(H_1) \ mi \neq mj$   

Nous avons lancé 10 tests simultanés, et obtenus les résulats suivants:   
  
```{r, echo=FALSE}
methodsRepetitive <- vector()
methodsNearestIns <- vector()
methods2Opt <- vector()
methodsNearest <- vector()
methodsBranch <- vector()

for (i in 1:50){
  methodsRepetitive<-c(methodsRepetitive, "repetitive_nn")
  methodsNearestIns<-c(methodsNearestIns, "nearest_insertion")
  methods2Opt<-c(methods2Opt, "two_opt")
  methodsNearest<-c(methodsNearest, "nearest")
  methodsBranch<-c(methodsBranch, "branch")
}
methods<-c(methodsRepetitive, methodsNearestIns, methods2Opt, methodsNearest, methodsBranch)
results<-c(cheminRepetitive, cheminNearestIns, chemin2Opt, cheminNearest, cheminBranch)

#test
pairwise.t.test(results,methods,adjust.method="bonferroni")
```
Nous allons tester si au seuil de 5%, notre hypothèse H0 est vérifiée.     

Si on accepte un risque alpha=5%, on rejette notre hypothèse nulle ($H_0$) si la $p_{valeur}$ obtenue à l'indice [i,j] est inférieure à alpha.   
Donc, si la valeur à l'indice [i,j] est inférieure à alpha, nous pouvons affirmer avec un risque de 5% que la moyenne des chemins hamiltoniens obtenus avec la méthode i est différente de celle obtenue avec la méthode j.  

En appliquant ce principe à nos résultats, nous pouvons dire que :

- les méthodes \texttt{nearest} et \texttt{branch} ont des moyennes de chemins calculés différentes
- les méthodes \texttt{nearest\_insertion} et \texttt{branch} ont des moyennes de chemins calculés différentes 
- les méthodes \texttt{nearest} et \texttt{repetitive\_nn} ont des moyennes de chemins calculés différentes
  
Pour les autres méthodes, nous ne pouvons pas rejeter l'hypothèse d'après laquelle la moyenne des chemins hamiltoniens obtenus avec la méthode i est égale à la moyenne des chemins hamiltoniens obtenus avec la méthode j.

## 1.2. Temps de calcul

Nous souhaitons maintenant comparer les temps d'éxécution des différentes méthodes de calcul de longueur de chemin hamiltonien sur 20 graphes de 10 sommets générés aléatoirement.  

Nous avons utilisé la fonction benchmark pour réaliser des statistiques d'exécution pour chaque méthode.   
  
Nous avons réalisé des tests sur les temps moyens d'exécution de chaque méthode :   
Soit i, j deux méthodes différentes .Notre hypothèse nulle $H_0$ est que le temps moyen d'exécution de la méthode i est égale au temps moyen d'exécution de la méthode j. Notre hypothèse alternative ($H_1$) est que le temps moyen d'exécution de la méthode i est différent du temps moyen d'exécution de la méthode j.  

$(H_0)\ mi = mj$   
$(H_1)\ mi \neq mj$
  
Le résultat de ces tests est représenté par une lettre dans la colonne cld du tableau ci-dessous. Une même lettre est attribuée aux méthodes pour lequelles $H_0$ n'est pas rejetée. Les lettres sont classées par ordre croissant de temps d'exécution, ainsi un algorithme classé 'a' est plus rapide qu'un algoriyhme classé 'b', etc ...  
Deux méthodes ayant des lettres différentes ont donc des temps d'exécution moyens différents.  

```{r, echo=FALSE}
microbenchmark(TSPsolve(couts,"repetitive_nn"), TSPsolve(couts,"nearest_insertion"), TSPsolve(couts,"two_opt"), TSPsolve(couts,"nearest"), TSPsolve(couts,"branch"), 
               times=20, 
               setup={
                 n <- 10
                 sommets <- data.frame(x = runif(n), y = runif(n))
                 couts <- distance(sommets)
                }
            )
```
Nous pouvons remarquer que les méthodes \texttt{nearest\_insertion}, \texttt{two\_opt} et \texttt{nearest} ont des temps d'exécution moyens similaires. Les méthodes sont classées 'a', ce qui montre que ce sont les méthodes les plus rapides des 5 méthodes proposées. De plus, les 3 méthodes ayant le même classement, on ne peut pas rejeter le fait que les temps moyens d'exécution de ces méthode sont équivalents. Il n'a, en tout cas, pas été mis en évidence que ces méthodes avaient des temps d'exécution significativement différents.     
Les méthodes \texttt{repetitive\_nn} et \texttt{branch} ont une durée d'exécution moyenne supérieure aux autres.
  
La méthode repetitive_nn est classée 'c', ce qui fait que l'on peut affirmer que le temps moyen d'exécution de cette méthode est différent du temps moyen d'exécution des autres méthodes. De plus, comme les lettres {a, b, c, ...} sont attribuées en fonction du temps d'exécution ('a' pour la plus rapide, ...), on peut en déduire que le temps moyen d'exécution de \texttt{repetitive\_nn} est plus important que le temps moyens des autres méthodes.  
  
Par la même réflexion que celle faite précédemment, nous pouvons remarquer que \texttt{branch} est classé 'b', et a un temps d'exécution moyen plus long que les trois méthodes classées 'a'. Cependant, il a un temps moyen d'exécution inférieur à la méthode \texttt{repetitive\_nn}.

# 2. Etude de la complexité de l'algorithme Branch and Bound

Nous nous intéressons désormais à l'algorithme Branch&Bound. Nous allons étudier sa complexité en fonction du graphe sur lequel il est appliqué.  

```{r, echo=FALSE}
n <- 10
sommets <- data.frame(x = runif(n), y = runif(n))
couts <- distance(sommets)
```

## 2.1. Comportement par rapport au nombre de sommets : premier modèle

```{r, echo=FALSE}
seq_max <- 20
seqn <- seq(4,seq_max,1)
number_exec <- seq_max-3

temps<-matrix(,nrow = number_exec, ncol = 10)
for (i in 1:number_exec){
  temps[i,]<-microbenchmark(TSPsolve(couts, method = "branch"),
                            times = 10,
                            setup = { n <- seqn[i]
                            couts <- distance(cbind(x = runif(n), y = runif(n)))}
                            )$time
}
```

### Création du modèle linéaire
Dans un premier temps nous allons créer une matrice temps calculant les temps mis par l'algorithme Branch&Bound pour calculer les chemins hamiltoniens sur un graphe de $n$ sommets généré aléatoirement. Nous réalisons 10 fois l'algorithme sur un graphe à $n$ sommets, et nous faisons varier $n$ de 4 à 20. La matrice obtenue est donc de dimension $17*10$.  
  
A l'aide de ces données, nous pouvons afficher le graphe du temps mis par l'algorithme en fonction du nombre de noeuds du graphe, et le graphe de $\log(temps)^2$ en fonction nombre de noeuds du graphe. Cela nous donne les résultats ci-dessous.

```{r, echo=FALSE}
par(mfrow=c(1,2)) 
matplot(seqn, temps, xlab="n", ylab="temps")
matplot(seqn, log(temps)^2, xlab="n", ylab=expression(log(temps)^2))
```

Le graphe du temps mis par l'algorithme en fonction du nombre de noeuds du graphe semble suivre une courbe exponentielle. Cette hypothèse est soutenue par le 2ème graphe.  
  
Nous avons ensuite ajusté le modèle linéaire de $\log(temps)^2$ en fonction de $n$, pour en récupérer les principales charactéristiques. Nous avons obtenu le résultat suivant :  

```{r, echo=FALSE}
vect_temps <- log(as.vector(temps))^2
vect_dim <- rep(seqn,times=10)
temps.lm <- lm(vect_temps~vect_dim)
summary(temps.lm)
```
Nous pouvons remarquer qu'il y a une relation linéaire entre $\log(temps)²$ et $n$, puisque le test de Fisher ne rejette pas le modèle linéaire. En effet ce test permet de rejeter le fait que tous les coefficients du modèle sont nuls.  
De plus, $R^2$ =

```{r, echo=FALSE}
summary(temps.lm)$r.squared
```
$R²$ étant proche de 1, une grande partie des données suivent le modéle linéaire. On peut donc en conclure qu'il y a une relation linéaire entre $\log(temps)^2$ et $n$.  
  
De ce fait, on peut en déduire que :   
$\exists \alpha, \beta$ tels que $\log(temps)²=\alpha*n+\beta$   
soit $\log(temps)=^+_-\sqrt(\alpha*n+\beta)$  
donc $temps=\exp(^+_-\sqrt(\alpha*n+\beta))$  
  
On peut en déduire que Branch&Bound semble avoir une complexité temporelle en $\exp(n)$.

### Analyse de la validité du modèle : 

Le modèle nous renvoie une fonction de type: $Y = aX + b + \epsilon$. En effet nous avons les paramètres suivants:   

 *  $a$ =  

```{r, echo=FALSE}
summary(temps.lm)$coefficients[2]
```

 *  $b$ = 

```{r, echo=FALSE}
summary(temps.lm)$coefficients[1]
```

Il reste donc à savoir si les coéfficients et donc le modèle sont pertinents. Nous allons tous d'abord analyser la pertinence des coefficients puis celle du modèle en géneral.   

 * Soit $\alpha = 5\%$

  * L'analyse de $a$, permet d'établir un premier résultat quantifiant la significativité du modèle. En effet nous allons tester la significativité de $a$ via le test statistique: $(H_0) : a = 0$ contre $(H_1) : a \neq 0$. La $p_{value}$ de celui-ci ce retrouve dans le tableau summary(temps.lm) et est 
  
```{r, echo=FALSE}
summary(temps.lm)$coef[,"Pr(>|t|)"][2]
```
  
   Nous pouvons donc rejeter $H_0$  et affirmer avec 5% de risque que $a$ est significatif. 
  * L'analyse de $b$ est la moins importante. Il nous indique seulement l'importance de l'intercept. Le test statistique est analogique à $a$. Sa $p_{value}$ est
  
```{r, echo=FALSE}
summary(temps.lm)$coef[,"Pr(>|t|)"][1]
```

  
  Nous pouvons donc rejeter $H_0$  et affirmer avec 5% de risque que $b$ est significatif.  
  * Nous pouvons maintenant passer à l'analyse des résidus: 
    * Pour ceci nous allons tous d'abord nous intérésser à plusieurs graphique:

```{r, echo=FALSE}
par(mfrow=c(2,2)) 
plot(temps.lm)
```
 
 
 * Residuals vs Fitted: La courbe n'est pas complètement horizontale. Il y'a donc un léger effet d'échelle. 
 * Normal Q-Q: les points sont proches de la bissectrice, la distribution des résidus est donc similaire à la distribution normale. Nous voyons une légère séparation au niveau des queues des distribution. 
 * Scale Location: cette courbe représente la même chose que la première seulement avec des résisus normalisés. On remarque que la courbe est bien honrizontale et que le léger effet d'échelle disparaît. 
 * Pour la distance de cook nous avons préféré prendre le graphique suivant: Nous voyons qu'aucun résidu a une distance plus grande que 0.05 et que la plupart ont une distance inferieure à 0.01. Ceci montre que le modèle est bien choisi.
 
 
```{r, echo=FALSE}
plot(temps.lm,which=4)
```

  * Il est aussi possible d'éffectuer un test statistique sur les résidus. En effet le fait qu'ils suivent une loi normale indique la qualité du modèle. 
  * Définissons: 
    * $(H_0)$ les résidus suivent une loi normale
    * $(H_1)$ les résidus ne suivent pas une loi normale
  * Pour tester ceci nous pouvons efféctuer un test de shapiro. 
  

```{r, echo=FALSE}
shapiroTest<-shapiro.test(residuals(temps.lm))
print(shapiroTest)
```

```{r, echo=FALSE}
#risque 5%
alpha=0.05
if(shapiroTest$p.value < alpha){
  print("p-valeur < alpha")
  print("On peut rejeter H0")
}else{
  print("p-valeur >= alpha")
  print("On ne peut pas rejeter H0")
}
```
On ne peut pas rejetter $H_0$, donc nous pouvons affirmer avec un risque de 5% que les résidus ne suivent pas une loi normale. Ce qui indique un modèle pertinent. 


## 2.2. Comportement par rapport au nombre de sommets : étude du comportement moyen
L'explication des résultats étant similaire à 2.1, nous allons simplement afficher nos résultats.  
Récupération du temps moyen.

```{r, echo=FALSE}
temps.moy<-rowMeans(temps)
```

Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de $n$.

```{r, echo=FALSE}
vect_temps_moy <- log(as.vector(temps.moy))^2
vect_dim_moy <- rep(seqn)
temps.lm_moy <- lm(vect_temps_moy~vect_dim_moy)
summary(temps.lm_moy)
```

Analyse de la validité du modèle : 

  * $a$ pertinent $p_{value}$ =  
  
  
```{r, echo=FALSE}
summary(temps.lm_moy)$coef[,"Pr(>|t|)"][2]
```
  
  * $b$ pertinent $p_{value}$ =  
  
  
```{r, echo=FALSE}
summary(temps.lm_moy)$coef[,"Pr(>|t|)"][1]
```
  
```{r, echo=FALSE}
par(mfrow=c(2,2)) 
plot(temps.lm_moy)
```

 
 * Residuals vs Fitted: La courbe n'est pas du tout horizontale. Il y'a donc un important effet d'échelle. 
 * Normal Q-Q: Les distributions sont identiques.
 * Scale Location: L'effet d'échelle disparait. Le nuage de points est sans structure. Ce qui indique la qualité du modèle. 

  
  * Il est aussi possible d'effectuer un test statistique sur les résidus. En effet le fait q'ils suivent une loi normale indique le bon fit du modèle. 
  * Définissons: 
    * $(H_0)$ les résidus suivent une loi normale
    * $(H_1)$ les résidus ne suivent pas une loi normale
  * Pour tester ceci nous pouvons effectuer un test de shapiro. 
  

On prend un risque alpha=5%
  
```{r, echo=FALSE}
shapiroTest_moy<-shapiro.test(residuals(temps.lm_moy))
print(shapiroTest_moy)
```

```{r, echo=FALSE}
#risque 5%
alpha=0.05
if(shapiroTest_moy$p.value < alpha){
  print("p-valeur < alpha")
  print("On peut rejeter H0")
}else{
  print("p-valeur >= alpha")
  print("On ne peut pas rejeter H0")
}
```
On ne peut rejetter $H_0$, donc nous pouvons affirmer avec un risque de 5% que les résidus suivent une loi normale. Ce qui indique un modèle pertinent. 

## 2.3. Comportement par rapport à la structure du graphe

```{r, echo=FALSE}
data.graph <- data.frame(read.csv('DonneesTSP.csv'))
data.graph$dim<-sqrt(data.graph$dim)
```
 * D'après nous les variables non pertinentes sont: diameter, mean.dist, sd.dist, mean.long. En effet tous ces variables s'intérèssent seulement aux coûts des arrêtes. Ces dernières n'ont pas d'importance dans le temps de calcul (calculer le chemin avec une arrete de 5 ou de 1000 reviens à la même chose). 

 * Ajustement du modèle linéaire de $\log(temps.moy)$ en fonction de toutes les variables présentes. Modèle sans constante. Nous allons d'abord procéder à un test de fisher avec toutes les variables. 

```{r, echo=FALSE}
model.complete <- lm(log(tps)~., data = data.graph)
summary(model.complete)
```
* Soit $\alpha = 1\%$
* Le test de fisher à une $p_{value}$ de $2*10{^-16}$ et nous permet donc de rejeter $_H0$ avec un risque de $1\%$.

### Calcul AIC
* Dans l'étape suivante nous allons procéder au calcul de l'AIC pour les variables de notre modèle. Ceci nous permettera de supprimer les variables non pertinentes.
```{r, echo=FALSE}
(step(model.complete))
```

* La variable diameter a été supprimée du modèle. Il reste sd.dist, mean.dist et mean.long, qui nous paraissent peu pertinente. 

### Test Fisher 

```{r, echo=FALSE}
new_model <- lm(formula = log(tps) ~ dim + mean.long + mean.dist + sd.dist + 
    mean.deg + sd.deg, data = data.graph)
summary(new_model)
```

 * Soit $\alpha = 1\%$.
 * D'après le test de fisher nous pouvons affirmer que le test est pertinent avec un risque de $1\%$ ($p_{value}  =2.2*10^{-16}$). Cependant la $p_{value}$ n'a pas changé en supprimant la variable diameter.
 
### Plots

```{r, echo=FALSE}
par(mfrow=c(2,2)) 
plot(new_model)
```

 * Residuals vs Fitted: La courbe n'est pas horizontale. Il y'a donc un effet d'échelle. Ceci indique un fit moyen.
 * Normal Q-Q: Les distributions sont identiques, avec de légères différences sur les queues. 
 * Scale Location: L'effet d'échelle disparaît. Le nuage de points est sans structure. Ce qui indique la qualité du modèle. 
 * Cook Distance: les points sont à une distance de cook faible, ceci indique un bon fit. 
 
### Test Shapiro 
 * Nous pouvons aussi analyser les résidus, pour voir s'ils suivent une distribution normale, avec le test de Shapiro.

```{r, echo=FALSE}
new_model <- lm(formula = log(tps) ~ dim + mean.long + mean.dist + sd.dist + 
    mean.deg + sd.deg, data = data.graph)
shapiroTest_aic<-shapiro.test(residuals(new_model))
print(shapiroTest_aic)
```
```{r, echo=FALSE}
#risque 5%
alpha=0.05
if(shapiroTest_moy$p.value < alpha){
  print("p-valeur <= alpha")
  print("On peut rejeter H0")
}else{
  print("p-valeur > alpha")
  print("On ne peut pas rejeter H0")
}
```
On ne peut pas rejeter $H_0$, donc nous pouvons affirmer avec un risque de 5% que les résidus suivent une loi normale. Ce qui indique un modèle pertinent. 
